import re
import tkinter as tk
from tkinter import Tk, messagebox, Label
import os

from municipality_selector_gui import select_municipality
from municipality_detector import detect_municipality_name
from search_strategy_detector import detect_search_strategy_candidates

from search_types.google_cse import search as google_cse_search
from search_types.internal_search import search as internal_search
from search_types.topical_entry import search as topical_entry_search
from search_types.hierarchical_entry import search as hierarchical_entry_search
from search_types.fallback import search as fallback_search
from search_types.sitemap import search as sitemap
from search_types.google_broad_search import search as google_broad_search

from link_extractor import extract_links, save_links_csv
from deep_pdf_finder import find_pdfs_recursively
from result_collector import save_results
from pdf_selector_gui import show_pdf_selector


# ==========================================
# è¨­å®š
# ==========================================
MAX_PAGES = 5
LINKS_CSV = r"C:\Users\matsu\Desktop\python\urban_mp_research\output\links.csv"

SEARCH_FUNCS = {
    "google_cse": google_cse_search,
    "internal_search": internal_search,
    "topical_entry": topical_entry_search,
    "hierarchical_entry": hierarchical_entry_search,
    "fallback": fallback_search,
    "sitemap": sitemap,
    "google_broad": google_broad_search,
}

root = None  # Tkã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹


# ==========================================
# ãƒ­ãƒœãƒƒãƒˆåˆ¤å®šæ™‚ã®æ‰‹å‹•å¾…æ©Ÿ
# ==========================================
def wait_for_manual_robot_action(strategy: str):
    pass
    # å¿…è¦ãªã‚‰ messagebox ã‚’å¾©æ´»å¯èƒ½


# ==========================================
# 1è‡ªæ²»ä½“åˆ†ã®å‡¦ç†
# ==========================================
def run_once():
    global root

    selection = select_municipality(root)
    if selection is None:
        print("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
        return False

    url = selection.get("url")
    municipality = selection.get("municipality")

    if not url:
        messagebox.showerror("ã‚¨ãƒ©ãƒ¼", "URLãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return False

    url = url.strip()
    if not re.match(r"^https?://", url, re.IGNORECASE):
        messagebox.showerror("ã‚¨ãƒ©ãƒ¼", "æœ‰åŠ¹ãªURLã§ã¯ã‚ã‚Šã¾ã›ã‚“")
        return False

    city = municipality or detect_municipality_name(url)
    print(f"\nğŸ™ è‡ªæ²»ä½“: {city}")
    print(f"ğŸŒ URL: {url}")

    # ----------------------------------
    # æ¤œç´¢ä¸­ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
    # ----------------------------------
    loading_win = tk.Toplevel(root)
    loading_win.title("å®Ÿè¡Œä¸­")
    loading_win.geometry("600x180+800+150")
    loading_win.attributes("-topmost", True)

    Label(loading_win, text=f"{city}ã‚’æ¤œç´¢", font=("MS Gothic", 14, "bold")).pack(
        pady=(20, 5)
    )
    status_label = Label(loading_win, text="æ¤œç´¢ä¸­â€¦", font=("MS Gothic", 13))
    status_label.pack(pady=10)
    loading_win.update()

    # ----------------------------------
    # æ¤œç´¢æ–¹å¼ã®æ±ºå®š
    # ----------------------------------
    strategies = ["hierarchical_entry", "internal_search", "google_cse", "sitemap"]
    detected = detect_search_strategy_candidates(url)
    for s in detected:
        if s not in strategies and s in SEARCH_FUNCS:
            strategies.append(s)

    final_links = []
    used_strategy = None

    # ----------------------------------
    # æ¤œç´¢æ–¹å¼ãƒ«ãƒ¼ãƒ—
    # ----------------------------------
    for strategy in strategies:
        if strategy == "google_broad":
            continue

        print(f"â–¶ æ¤œç´¢æ–¹å¼: {strategy}")
        status_label.config(text=f"{strategy} ã§æ¤œç´¢ä¸­â€¦")
        loading_win.update()

        func = SEARCH_FUNCS.get(strategy)
        if not func:
            continue

        try:
            if strategy in ("google_cse", "internal_search"):
                result = func(start_url=url, max_pages=MAX_PAGES)
            else:
                result = func(start_url=url)

            if not result:
                print(f"âš  {strategy} çµæœãªã— â†’ æ¬¡ã¸")
                continue

            # --- ãƒªãƒ³ã‚¯æŠ½å‡º ---
            if strategy in ("topical_entry", "hierarchical_entry", "sitemap"):
                current_links = [(u, u) for u in result]
            else:
                current_links = extract_links(result)

            if not current_links:
                print(f"âš  {strategy} ãƒªãƒ³ã‚¯0ä»¶ â†’ æ¬¡ã¸")
                continue

            # --- PDFãŒå®Ÿåœ¨ã™ã‚‹ã‹è»½ãç¢ºèª ---
            test_records = []
            for _, test_link in current_links[:3]:
                try:
                    depth = 1 if test_link.lower().endswith(".pdf") else 2
                    found = find_pdfs_recursively(
                        start_url=test_link, city=city, max_depth=depth
                    )
                    test_records.extend(found)
                except Exception:
                    pass

            if test_records:
                final_links = current_links
                used_strategy = strategy
                print(f"âœ… {strategy} ã§PDFç¢ºèª")
                break
            else:
                print(f"âš  {strategy} PDF 0ä»¶ â†’ æ¬¡ã®æ¤œç´¢æ–¹å¼ã¸")

        except Exception as e:
            print(f"âš  {strategy} ã‚¨ãƒ©ãƒ¼: {e}")
            wait_for_manual_robot_action(strategy)

    # ----------------------------------
    # æ¤œç´¢å¤±æ•—
    # ----------------------------------
    if not used_strategy:
        loading_win.destroy()
        messagebox.showerror("ã‚¨ãƒ©ãƒ¼", "æœ‰åŠ¹ãªæ¤œç´¢æ–¹å¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return True

    # ----------------------------------
    # ãƒªãƒ³ã‚¯ä¿å­˜
    # ----------------------------------
    save_links_csv(final_links, LINKS_CSV)

    # ----------------------------------
    # æœ¬æ ¼PDFæ¢ç´¢
    # ----------------------------------
    records = []
    for title, link in final_links:
        try:
            depth = 1 if link.lower().endswith(".pdf") else 4
            records.extend(find_pdfs_recursively(link, city, max_depth=depth))
        except Exception:
            pass

    # ----------------------------------
    # PDF 0ä»¶ â†’ GoogleåºƒåŸŸæ¤œç´¢
    # ----------------------------------
    if not records:
        try:
            broad_results = google_broad_search(city)
            for title, link in broad_results or []:
                if link.lower().endswith(".pdf"):
                    records.append(
                        {
                            "title": title or os.path.basename(link),
                            "url": link,
                            "source": "google_broad_direct",
                            "depth": 0,
                        }
                    )
                else:
                    records.extend(find_pdfs_recursively(link, city, max_depth=3))
        except Exception as e:
            print(f"âš  GoogleåºƒåŸŸæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")

    loading_win.destroy()

    if not records:
        messagebox.showwarning(
            "è­¦å‘Š",
            "é–¢é€£ã™ã‚‹PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n"
            "ï¼ˆè‡ªæ²»ä½“æœªå…¬é–‹ãƒ»æ§‹é€ å·®ç•°ã®å¯èƒ½æ€§ï¼‰",
        )
        return True

    save_results(records)
    show_pdf_selector()
    return True


# ==========================================
# ãƒ¡ã‚¤ãƒ³
# ==========================================
def main():
    global root
    root = Tk()
    root.withdraw()

    while True:
        if not run_once():
            break

        if not messagebox.askyesno("å®Œäº†", "åˆ¥ã®è‡ªæ²»ä½“ã‚’ç¶šã‘ã¦æ¤œç´¢ã—ã¾ã™ã‹ï¼Ÿ"):
            break

    root.destroy()


if __name__ == "__main__":
    main()
