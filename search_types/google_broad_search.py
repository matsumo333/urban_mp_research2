import time
import urllib.parse
import re
import csv
import os
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By

SEARCH_WORD = "éƒ½å¸‚è¨ˆç”» ãƒã‚¹ã‚¿ãƒ¼ãƒ—ãƒ©ãƒ³"
LINKS_CSV_PATH = "../output/links.csv"  # ç›¸å¯¾ãƒ‘ã‚¹ï¼ˆ1ã¤ä¸Šã®outputãƒ•ã‚©ãƒ«ãƒ€ï¼‰


def clean_title(raw_text: str) -> str:
    """ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ä½™è¨ˆãªURLã‚„è¨˜å·ã‚’é™¤å»"""
    lines = [l.strip() for l in raw_text.splitlines() if l.strip()]
    cleaned = []
    for line in lines:
        if re.search(r"https?://|www\.|â€º", line):
            continue
        cleaned.append(line)
    return cleaned[0] if cleaned else "ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãªã—ï¼‰"


def save_links_to_csv(links):
    """CSVã«å®Œå…¨URLã§ä¿å­˜"""
    output_dir = os.path.dirname(LINKS_CSV_PATH)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)

    with open(LINKS_CSV_PATH, "w", encoding="utf-8-sig", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["title", "url"])  # ãƒ˜ãƒƒãƒ€ãƒ¼
        for title, url in links:
            writer.writerow([title, url])
    print(f"ğŸ’¾ å®Œå…¨URLã§ãƒªãƒ³ã‚¯ä¿å­˜å®Œäº†: {LINKS_CSV_PATH}ï¼ˆ{len(links)}ä»¶ï¼‰")


def search(city_name: str) -> list[tuple[str, str]]:
    """
    äººé–“ã‚‰ã—ã„GoogleåºƒåŸŸæ¤œç´¢
    - city_name: è‡ªæ²»ä½“åï¼ˆä¾‹: "æ¨ªæµœå¸‚", "æ±äº¬éƒ½ä¸­å¤®åŒº"ï¼‰
    - æˆ»ã‚Šå€¤: [(title, url), ...] ã®ãƒªã‚¹ãƒˆ
    """
    if not city_name:
        print("âš  è‡ªæ²»ä½“åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return []

    options = Options()
    options.add_argument("--window-size=1200,900")
    # options.add_argument("--headless")  # å¿…è¦ã«å¿œã˜ã¦

    driver = webdriver.Chrome(options=options)
    results = []

    try:
        # å…¬å¼ã‚µã‚¤ãƒˆé™å®šæ¤œç´¢
        query = f'"{city_name}" {SEARCH_WORD} site:.go.jp OR site:.lg.jp'
        encoded = urllib.parse.quote(query)
        search_url = f"https://www.google.com/search?q={encoded}&num=30"

        print(f"\nğŸ” æ¤œç´¢é–‹å§‹: {city_name}")
        print("   GoogleãŒé–‹ãã¾ã™ã€‚ãƒ­ãƒœãƒƒãƒˆèªè¨¼ãŒå‡ºãŸã‚‰æ‰‹å‹•ã§è§£é™¤ã—ã¦ãã ã•ã„")
        print("   30ç§’å¾Œã«è‡ªå‹•ã§çµæœã‚’åé›†ã—ã¾ã™...\n")

        driver.get(search_url)
        time.sleep(30)  # æ‰‹å‹•å¯¾å¿œç”¨å¾…æ©Ÿ

        print("ğŸ”„ æ¤œç´¢çµæœã‚’è§£æä¸­...")

        for a in driver.find_elements(By.CSS_SELECTOR, "a"):
            href = a.get_attribute("href")
            if not href:
                continue
            if any(
                x in href
                for x in ["google.com", "youtube.com", "policies", "preferences"]
            ):
                continue
            if href.startswith(("javascript:", "data:")):
                continue
            if not re.search(r"\.(go\.jp|lg\.jp)/", href):
                continue

            raw_title = a.text.strip()
            title = clean_title(raw_title)
            if not title or title == "ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãªã—ï¼‰":
                try:
                    h3 = a.find_element(By.XPATH, ".//h3")
                    title = h3.text.strip()
                except:
                    title = "ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãªã—ï¼‰"

            results.append((title, href))

        # é‡è¤‡é™¤å»
        seen = set()
        unique = []
        for t, u in results:
            if u not in seen:
                unique.append((t, u))
                seen.add(u)

        save_links_to_csv(unique)
        print(f"âœ… æ¤œç´¢å®Œäº†ï¼å…¬å¼é–¢é€£ãƒšãƒ¼ã‚¸ {len(unique)}ä»¶ã‚’ç™ºè¦‹ãƒ»ä¿å­˜ã—ã¾ã—ãŸ")
        return unique

    except Exception as e:
        print(f"âš  æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return []
    finally:
        driver.quit()


# ================================
# å˜ç‹¬å®Ÿè¡Œæ™‚ã®å…¥åŠ›å¯¾å¿œï¼ˆä»–ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰importã•ã‚Œã¦ã‚‚é‚ªé­”ã«ãªã‚‰ãªã„ï¼‰
# ================================
if __name__ == "__main__":
    print("=== GoogleåºƒåŸŸæ¤œç´¢ãƒ„ãƒ¼ãƒ« ===\n")
    city = input(
        "è‡ªæ²»ä½“åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: å››æ—¥å¸‚å¸‚ã€æ¨ªæµœå¸‚ã€æ±äº¬éƒ½ä¸­å¤®åŒºï¼‰: "
    ).strip()
    if city:
        links = search(city)
        if links:
            print("\n=== ä¿å­˜ã•ã‚ŒãŸä¸»ãªãƒšãƒ¼ã‚¸ï¼ˆä¸Šä½10ä»¶ï¼‰ ===")
            for i, (title, url) in enumerate(links[:10], 1):
                print(f"{i}. {title}")
                print(f"   {url}\n")
    else:
        print("å…¥åŠ›ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
